{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'projekt' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n projekt ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#np_version = \"1.19.5\"  # Replace with the version you want to use\n",
    "#np = __import__(f\"numpy-{np_version}\", globals(), locals(), [], 0)\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yfinance'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\MirkoDzaja\\Documents\\faks\\projekt\\main.ipynb Cell 1\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MirkoDzaja/Documents/faks/projekt/main.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m warnings\u001b[39m.\u001b[39mfilterwarnings(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m, category\u001b[39m=\u001b[39m\u001b[39mFutureWarning\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MirkoDzaja/Documents/faks/projekt/main.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m#IMPORTS\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/MirkoDzaja/Documents/faks/projekt/main.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39myfinance\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39myf\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MirkoDzaja/Documents/faks/projekt/main.ipynb#W0sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MirkoDzaja/Documents/faks/projekt/main.ipynb#W0sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'yfinance'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "#IMPORTS\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy import stats\n",
    "import json\n",
    "from backtesting import Backtest, Strategy\n",
    "\n",
    "import utils.labeling_algorithm as labeling_algorithm\n",
    "import utils.la2 as la2\n",
    "from utils.features_util import compute_features, get_available_features\n",
    "from utils.cross_validation import custom_ten_fold_cv_selection, remove_monoton_instances, simple_ten_fold_cv_selection\n",
    "import utils.sample_weights as sample_weights_util\n",
    "import utils.xgb_utils as xgb_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMETERS\n",
    "symbols = ['AMD', 'CLX']\n",
    "start_date = '2019-11-30'\n",
    "end_date = '2021-11-15'\n",
    "#number of previous days to observe for next day's prediction\n",
    "window = 30\n",
    "\n",
    "close_prices = yf.download(symbols, start_date, end_date, progress=False)['Close']\n",
    "market_series = yf.download('SPY', start_date, end_date, progress=False)['Close']\n",
    "\n",
    "print(close_prices.shape)\n",
    "print(close_prices.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-state labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stock in symbols:\n",
    "    labels = labeling_algorithm.get_series_labels(close_prices[window:][stock], 0.05, 11)\n",
    "\n",
    "    plt.figure(figsize=(15, 5), facecolor='w')\n",
    "    plt.plot(close_prices[window:].index, close_prices[window:][stock])\n",
    "    plt.title('{} prices'.format(stock))\n",
    "    plt.show()\n",
    "    plt.figure(figsize=(15, 3), facecolor='w')\n",
    "    plt.plot(labels.index, labels)\n",
    "    plt.title('{} 3-state labels'.format(stock))\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-state labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stock in symbols:\n",
    "    labels = la2.get_series_labels(close_prices[window:][stock], 0.05)\n",
    "\n",
    "    plt.figure(figsize=(15, 5), facecolor='w')\n",
    "    plt.plot(close_prices[window:].index, close_prices[window:][stock])\n",
    "    plt.title('{} prices'.format(stock))\n",
    "    plt.show()\n",
    "    plt.figure(figsize=(15, 3), facecolor='w')\n",
    "    plt.plot(labels.index, labels)\n",
    "    plt.title('{} 2-state labels'.format(stock))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = get_available_features()\n",
    "#create 2-lavel column dataframe, first level is stock symbol, second level is feature name\n",
    "features_df = pd.DataFrame(columns = pd.MultiIndex.from_product([symbols, features]))\n",
    "\n",
    "for stock in symbols:\n",
    "    features_df[stock] = compute_features(stock, close_prices[stock], market_series, window)\n",
    "\n",
    "print(features_df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10-fold corss validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CVindices = simple_ten_fold_cv_selection(len(close_prices[window:]), window)\n",
    "\n",
    "plt.figure(figsize=(12, 8), facecolor='w')\n",
    "for i in range(0, len(CVindices)):\n",
    "    trainIndices = CVindices[i][0]\n",
    "    valIndices = CVindices[i][1]\n",
    "\n",
    "    plt.plot(close_prices[window:].index[trainIndices], [i]*len(trainIndices), 'bo')\n",
    "    plt.plot(close_prices[window:].index[valIndices], [i]*len(valIndices), 'ro')\n",
    "\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CVindices = custom_ten_fold_cv_selection(len(close_prices[window:]), window)\n",
    "\n",
    "plt.figure(figsize=(12, 8), facecolor='w')\n",
    "for i in range(0, len(CVindices)):\n",
    "    trainIndices = CVindices[i][0]\n",
    "    valIndices = CVindices[i][1]\n",
    "\n",
    "    plt.plot(close_prices[window:].index[trainIndices], [i]*len(trainIndices), 'bo')\n",
    "    plt.plot(close_prices[window:].index[valIndices], [i]*len(valIndices), 'ro')\n",
    "\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample weights\n",
    "The greater the future profit/loss, the greater the sample weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock='CLX'\n",
    "labels = la2.get_series_labels(close_prices[window:][stock], 0.05)\n",
    "sample_weights = sample_weights_util.get(close_prices[window:][stock], labels)\n",
    "\n",
    "plt.figure(figsize=(15, 5), facecolor='w')\n",
    "plt.plot(close_prices[window:][stock].index, close_prices[window:][stock])\n",
    "plt.title('{} prices'.format(stock))\n",
    "plt.xlim(sample_weights.index[0], sample_weights.index[-1])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15, 5), facecolor='w')\n",
    "plt.plot(sample_weights.index, sample_weights)\n",
    "plt.title('{} sample weights'.format(stock))\n",
    "plt.xlim(sample_weights.index[0], sample_weights.index[-1])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15, 5), facecolor='w')\n",
    "plt.plot(labels.index, labels)\n",
    "plt.title('{} 2-state labels'.format(stock))\n",
    "plt.xlim(sample_weights.index[0], sample_weights.index[-1])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost for CLX with 2-state labeling algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = 'CLX'\n",
    "window = 30\n",
    "\n",
    "start_date_train = '2005-01-01'\n",
    "end_date_train = '2015-12-31'\n",
    "prices_train = yf.download(stock, start_date_train, end_date_train, progress=False)['Close']\n",
    "market_prices_train = yf.download('SPY', start_date_train, end_date_train, progress=False)['Close']\n",
    "\n",
    "start_date_test = '2016-01-01'\n",
    "end_date_test = '2017-12-31'\n",
    "prices_test = yf.download(stock, start_date_test, end_date_test, progress=False)['Close']\n",
    "market_prices_test = yf.download('SPY', start_date_test, end_date_test, progress=False)['Close']\n",
    "\n",
    "#FEATURES, 'X' of model\n",
    "features_train = compute_features(stock, prices_train, market_prices_train, window)\n",
    "features_test = compute_features(stock, prices_test, market_prices_test, window)\n",
    "\n",
    "#LABELS, 'Y' of model\n",
    "labels_train = la2.get_series_labels(prices_train[window:], 0.05)\n",
    "labels_train[labels_train == -1] = 0\n",
    "labels_test = la2.get_series_labels(prices_test[window:], 0.05)\n",
    "labels_test[labels_test == -1] = 0\n",
    "\n",
    "counts, values = np.unique(labels_train, return_counts=True)\n",
    "\n",
    "#SAMPLE WEIGHTS\n",
    "sw_train = sample_weights_util.get(prices_train[window:], labels_train)\n",
    "sw_test = sample_weights_util.get(prices_test[window:], labels_test)\n",
    "\n",
    "#CROSS VALIDATION INDICES\n",
    "cv_inidces_list = custom_ten_fold_cv_selection(len(prices_train[window:]), window)\n",
    "cv_inidces_list = remove_monoton_instances(cv_inidces_list, labels_train)\n",
    "\n",
    "#SCALE POS WEIGHT\n",
    "pos_weight = np.sum(labels_train == 0) / np.sum(labels_train == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple model:\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\MirkoDzaja\\Documents\\faks\\projekt\\main.ipynb Cell 16\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MirkoDzaja/Documents/faks/projekt/main.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mSimple model:\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/MirkoDzaja/Documents/faks/projekt/main.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m xgb_utils\u001b[39m.\u001b[39;49mbayes_search_cv_custom(features_train, labels_train, cv_inidces_list, saving_file\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msaved_models/bayes/\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m_simple.json\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mformat(stock))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MirkoDzaja/Documents/faks/projekt/main.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mClass balancing model:\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MirkoDzaja/Documents/faks/projekt/main.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m xgb_utils\u001b[39m.\u001b[39mbayes_search_cv_custom(features_train, labels_train, cv_inidces_list, scale_pos_weight\u001b[39m=\u001b[39mpos_weight, saving_file\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msaved_models/bayes/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m_class_balancing.json\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(stock))\n",
      "File \u001b[1;32mc:\\Users\\MirkoDzaja\\Documents\\faks\\projekt\\utils\\xgb_utils.py:117\u001b[0m, in \u001b[0;36mbayes_search_cv_custom\u001b[1;34m(features_train, labels_train, cv_inidces_list, param_grid, sw_train, scale_pos_weight, saving_file)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mif\u001b[39;00m sw_train \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m     fit_params[\u001b[39m'\u001b[39m\u001b[39msample_weight\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m sw_train\n\u001b[1;32m--> 117\u001b[0m clf\u001b[39m.\u001b[39;49mfit(features_train, labels_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[0;32m    118\u001b[0m \u001b[39mif\u001b[39;00m scale_pos_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    119\u001b[0m     clf\u001b[39m.\u001b[39mbest_params_[\u001b[39m'\u001b[39m\u001b[39mscale_pos_weight\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m scale_pos_weight\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\skopt\\searchcv.py:466\u001b[0m, in \u001b[0;36mBayesSearchCV.fit\u001b[1;34m(self, X, y, groups, callback, **fit_params)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    464\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer_kwargs_ \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer_kwargs)\n\u001b[1;32m--> 466\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(X\u001b[39m=\u001b[39;49mX, y\u001b[39m=\u001b[39;49my, groups\u001b[39m=\u001b[39;49mgroups, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[0;32m    468\u001b[0m \u001b[39m# BaseSearchCV never ranked train scores,\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[39m# but apparently we used to ship this (back-compat)\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_train_score:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\skopt\\searchcv.py:512\u001b[0m, in \u001b[0;36mBayesSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[39mwhile\u001b[39;00m n_iter \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    509\u001b[0m     \u001b[39m# when n_iter < n_points points left for evaluation\u001b[39;00m\n\u001b[0;32m    510\u001b[0m     n_points_adjusted \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(n_iter, n_points)\n\u001b[1;32m--> 512\u001b[0m     optim_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_step(\n\u001b[0;32m    513\u001b[0m         search_space, optimizer,\n\u001b[0;32m    514\u001b[0m         evaluate_candidates, n_points\u001b[39m=\u001b[39;49mn_points_adjusted\n\u001b[0;32m    515\u001b[0m     )\n\u001b[0;32m    516\u001b[0m     n_iter \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m n_points\n\u001b[0;32m    518\u001b[0m     \u001b[39mif\u001b[39;00m eval_callbacks(callbacks, optim_result):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\skopt\\searchcv.py:400\u001b[0m, in \u001b[0;36mBayesSearchCV._step\u001b[1;34m(self, search_space, optimizer, evaluate_candidates, n_points)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Generate n_jobs parameters and evaluate them in parallel.\u001b[39;00m\n\u001b[0;32m    398\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[39m# get parameter values to evaluate\u001b[39;00m\n\u001b[1;32m--> 400\u001b[0m params \u001b[39m=\u001b[39m optimizer\u001b[39m.\u001b[39;49mask(n_points\u001b[39m=\u001b[39;49mn_points)\n\u001b[0;32m    402\u001b[0m \u001b[39m# convert parameters to python native types\u001b[39;00m\n\u001b[0;32m    403\u001b[0m params \u001b[39m=\u001b[39m [[np\u001b[39m.\u001b[39marray(v)\u001b[39m.\u001b[39mitem() \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m p] \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m params]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:395\u001b[0m, in \u001b[0;36mOptimizer.ask\u001b[1;34m(self, n_points, strategy)\u001b[0m\n\u001b[0;32m    393\u001b[0m X \u001b[39m=\u001b[39m []\n\u001b[0;32m    394\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_points):\n\u001b[1;32m--> 395\u001b[0m     x \u001b[39m=\u001b[39m opt\u001b[39m.\u001b[39;49mask()\n\u001b[0;32m    396\u001b[0m     X\u001b[39m.\u001b[39mappend(x)\n\u001b[0;32m    398\u001b[0m     ti_available \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mps\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39macq_func \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(opt\u001b[39m.\u001b[39myi) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:367\u001b[0m, in \u001b[0;36mOptimizer.ask\u001b[1;34m(self, n_points, strategy)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Query point or multiple points at which objective should be evaluated.\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \n\u001b[0;32m    338\u001b[0m \u001b[39mn_points : int or None, default: None\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    364\u001b[0m \n\u001b[0;32m    365\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    366\u001b[0m \u001b[39mif\u001b[39;00m n_points \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 367\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ask()\n\u001b[0;32m    369\u001b[0m supported_strategies \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mcl_min\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcl_mean\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcl_max\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    371\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39misinstance\u001b[39m(n_points, \u001b[39mint\u001b[39m) \u001b[39mand\u001b[39;00m n_points \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\skopt\\optimizer\\optimizer.py:434\u001b[0m, in \u001b[0;36mOptimizer._ask\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    430\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_initial_points \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbase_estimator_ \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    431\u001b[0m     \u001b[39m# this will not make a copy of `self.rng` and hence keep advancing\u001b[39;00m\n\u001b[0;32m    432\u001b[0m     \u001b[39m# our random state.\u001b[39;00m\n\u001b[0;32m    433\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initial_samples \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 434\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mspace\u001b[39m.\u001b[39;49mrvs(random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrng)[\u001b[39m0\u001b[39m]\n\u001b[0;32m    435\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    436\u001b[0m         \u001b[39m# The samples are evaluated starting form initial_samples[0]\u001b[39;00m\n\u001b[0;32m    437\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initial_samples[\n\u001b[0;32m    438\u001b[0m             \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initial_samples) \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_initial_points]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\skopt\\space\\space.py:900\u001b[0m, in \u001b[0;36mSpace.rvs\u001b[1;34m(self, n_samples, random_state)\u001b[0m\n\u001b[0;32m    897\u001b[0m columns \u001b[39m=\u001b[39m []\n\u001b[0;32m    899\u001b[0m \u001b[39mfor\u001b[39;00m dim \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdimensions:\n\u001b[1;32m--> 900\u001b[0m     columns\u001b[39m.\u001b[39mappend(dim\u001b[39m.\u001b[39;49mrvs(n_samples\u001b[39m=\u001b[39;49mn_samples, random_state\u001b[39m=\u001b[39;49mrng))\n\u001b[0;32m    902\u001b[0m \u001b[39m# Transpose\u001b[39;00m\n\u001b[0;32m    903\u001b[0m \u001b[39mreturn\u001b[39;00m _transpose_list_array(columns)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\skopt\\space\\space.py:158\u001b[0m, in \u001b[0;36mDimension.rvs\u001b[1;34m(self, n_samples, random_state)\u001b[0m\n\u001b[0;32m    156\u001b[0m rng \u001b[39m=\u001b[39m check_random_state(random_state)\n\u001b[0;32m    157\u001b[0m samples \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rvs\u001b[39m.\u001b[39mrvs(size\u001b[39m=\u001b[39mn_samples, random_state\u001b[39m=\u001b[39mrng)\n\u001b[1;32m--> 158\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minverse_transform(samples)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\skopt\\space\\space.py:528\u001b[0m, in \u001b[0;36mInteger.inverse_transform\u001b[1;34m(self, Xt)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Inverse transform samples from the warped space back into the\u001b[39;00m\n\u001b[0;32m    524\u001b[0m \u001b[39m   original space.\u001b[39;00m\n\u001b[0;32m    525\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    526\u001b[0m \u001b[39m# The concatenation of all transformed dimensions makes Xt to be\u001b[39;00m\n\u001b[0;32m    527\u001b[0m \u001b[39m# of type float, hence the required cast back to int.\u001b[39;00m\n\u001b[1;32m--> 528\u001b[0m inv_transform \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m(Integer, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49minverse_transform(Xt)\n\u001b[0;32m    529\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(inv_transform, \u001b[39mlist\u001b[39m):\n\u001b[0;32m    530\u001b[0m     inv_transform \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(inv_transform)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\skopt\\space\\space.py:168\u001b[0m, in \u001b[0;36mDimension.inverse_transform\u001b[1;34m(self, Xt)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minverse_transform\u001b[39m(\u001b[39mself\u001b[39m, Xt):\n\u001b[0;32m    165\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Inverse transform samples from the warped space back into the\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \u001b[39m       original space.\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 168\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer\u001b[39m.\u001b[39;49minverse_transform(Xt)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\skopt\\space\\transformers.py:309\u001b[0m, in \u001b[0;36mPipeline.inverse_transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minverse_transform\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    308\u001b[0m     \u001b[39mfor\u001b[39;00m transformer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformers[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]:\n\u001b[1;32m--> 309\u001b[0m         X \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39;49minverse_transform(X)\n\u001b[0;32m    310\u001b[0m     \u001b[39mreturn\u001b[39;00m X\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\skopt\\space\\transformers.py:275\u001b[0m, in \u001b[0;36mNormalize.inverse_transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    273\u001b[0m X_orig \u001b[39m=\u001b[39m X \u001b[39m*\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhigh \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow\n\u001b[0;32m    274\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_int:\n\u001b[1;32m--> 275\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mround(X_orig)\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39;49mint)\n\u001b[0;32m    276\u001b[0m \u001b[39mreturn\u001b[39;00m X_orig\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\__init__.py:338\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    333\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    334\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIn the future `np.\u001b[39m\u001b[39m{\u001b[39;00mattr\u001b[39m}\u001b[39;00m\u001b[39m` will be defined as the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    335\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcorresponding NumPy scalar.\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFutureWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m    337\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39min\u001b[39;00m __former_attrs__:\n\u001b[1;32m--> 338\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[0;32m    340\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtesting\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    341\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtesting\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtesting\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "print('Simple model:')\n",
    "xgb_utils.bayes_search_cv_custom(features_train, labels_train, cv_inidces_list, saving_file='saved_models/bayes/{}_simple.json'.format(stock))\n",
    "print('Class balancing model:')\n",
    "xgb_utils.bayes_search_cv_custom(features_train, labels_train, cv_inidces_list, scale_pos_weight=pos_weight, saving_file='saved_models/bayes/{}_class_balancing.json'.format(stock))\n",
    "print('Sample weight model:')\n",
    "xgb_utils.bayes_search_cv_custom(features_train, labels_train, cv_inidces_list, sw_train=sw_train, saving_file='saved_models/bayes/{}_sample_weight.json'.format(stock))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All models are optimized with GridSearchCV.\n",
    "<br><br>\n",
    "'simple' - model with basic parameters without class/sample weighting\n",
    "<br>\n",
    "'simple_sw' - 'simple' model tested on sample weighted test data\n",
    "<br>\n",
    "'class_balan' - model with class balancing\n",
    "<br>\n",
    "'class_balan_sw' - 'class_balan' model tested on sample weighted test data\n",
    "<br>\n",
    "'sample_weight' - model with sample weighting\n",
    "<br>\n",
    "'sample_weight_sw' - 'sample_weight' model tested on sample weighted test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models testing for 'CLX' stock.\n",
      "                  Sample Weight Test       acc        f1       mse       auc\n",
      "simple                         False  0.505285  0.535714  0.494715  0.506035\n",
      "simple_sw                       True  0.498167  0.593888  0.501833  0.480107\n",
      "class_balan                    False  0.765328  0.769231  0.234672  0.765592\n",
      "class_balan_sw                  True  0.788277  0.816232  0.211723  0.780872\n",
      "sample_weight                  False  0.786469  0.800000  0.213531  0.787272\n",
      "sample_weight_sw                True  0.805379  0.836856  0.194621  0.794216\n"
     ]
    }
   ],
   "source": [
    "m_simple = xgb_utils.test_model(features_train, features_test, labels_train, labels_test, 'saved_models/{}_simple.json'.format(stock))\n",
    "m_simple_sw = xgb_utils.test_model(features_train, features_test, labels_train, labels_test, 'saved_models/{}_simple.json'.format(stock), sw_test=sw_test)\n",
    "m_class_balan = xgb_utils.test_model(features_train, features_test, labels_train, labels_test, 'saved_models/{}_class_balancing.json'.format(stock))\n",
    "m_class_balan_sw = xgb_utils.test_model(features_train, features_test, labels_train, labels_test, 'saved_models/{}_class_balancing.json'.format(stock), sw_test=sw_test)\n",
    "m_sample_weight = xgb_utils.test_model(features_train, features_test, labels_train, labels_test, 'saved_models/{}_sample_weight.json'.format(stock), sw_train=sw_train)\n",
    "m_sample_weight_sw = xgb_utils.test_model(features_train, features_test, labels_train, labels_test, 'saved_models/{}_sample_weight.json'.format(stock), sw_train=sw_train, sw_test=sw_test)\n",
    "\n",
    "m_df = pd.DataFrame(columns = ['Sample Weight Test', 'acc', 'f1', 'mse', 'auc'])\n",
    "m_df.loc['simple'] = [False] + list(m_simple.values())\n",
    "m_df.loc['simple_sw'] = [True] + list(m_simple_sw.values())\n",
    "m_df.loc['class_balan'] = [False] + list(m_class_balan.values())\n",
    "m_df.loc['class_balan_sw'] = [True] + list(m_class_balan_sw.values())\n",
    "m_df.loc['sample_weight'] = [False] + list(m_sample_weight.values())\n",
    "m_df.loc['sample_weight_sw'] = [True] + list(m_sample_weight_sw.values())\n",
    "\n",
    "print(\"Models testing for 'CLX' stock.\")\n",
    "print(m_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = 'CLX'\n",
    "window = 30\n",
    "refit_frequency = 5\n",
    "train_data_size = 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date_train = '2005-01-01'\n",
    "end_date_train = '2015-12-31'\n",
    "prices_train = yf.download(stock, start_date_train, end_date_train, progress=False)['Close']\n",
    "market_prices_train = yf.download('SPY', start_date_train, end_date_train, progress=False)['Close']\n",
    "#FEATURES, 'X' of model\n",
    "features_train = compute_features(stock, prices_train, market_prices_train, window)\n",
    "#LABELS, 'Y' of model\n",
    "labels_train = la2.get_series_labels(prices_train[window:], 0.05)\n",
    "labels_train[labels_train == -1] = 0\n",
    "\n",
    "with open('saved_models/{}_simple.json'.format(stock), 'r') as fp:\n",
    "    model_params = json.load(fp)\n",
    "xgb_model = xgb.XGBClassifier(**model_params)\n",
    "xgb_model.fit(features_train, labels_train)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "class XGB2StateStrategy(Strategy):\n",
    "    \n",
    "    \n",
    "    def init(self):\n",
    "        self.window_size = window\n",
    "        self.model = xgb_model\n",
    "        self.feature_labels = get_available_features()\n",
    "        self.refit_frequency = refit_frequency\n",
    "        self.counter = 0\n",
    "        self.train_data_size = train_data_size\n",
    "        self.X_train = features_train\n",
    "        self.Y_train = labels_train\n",
    "    \n",
    "    def next(self):\n",
    "        self.counter += 1\n",
    "        if self.counter == self.refit_frequency:\n",
    "            self.X_train = self.X_train[-self.train_data_size:]\n",
    "            self.Y_train = self.Y_train[-self.train_data_size:]\n",
    "            self.model.fit(self.X_train, self.Y_train)\n",
    "            self.counter = 0\n",
    "        \n",
    "        X_test = self.data.df[self.feature_labels].tail(1)\n",
    "        prediction = self.model.predict(X_test)[0]\n",
    "        \n",
    "        self.X_train.append(X_test)\n",
    "        self.Y_train = np.append(self.Y_train, self.data.df['Label'].tail(1))\n",
    "        predictions.append(prediction)\n",
    "        \n",
    "        if prediction == 1:\n",
    "            if self.position.is_short or not self.position:\n",
    "                self.position.close()\n",
    "                self.buy()\n",
    "        else:\n",
    "            if self.position.is_long or not self.position:\n",
    "                self.position.close()\n",
    "                self.sell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2016-01-01' #actual starting date is window_size working days after this date\n",
    "end_date = '2023-01-01'\n",
    "stock_prices_df = yf.download(stock, start_date, end_date, progress=False)[['Open', 'High', 'Low', 'Close', 'Volume']]\n",
    "market_close_df = yf.download('SPY', start_date, end_date, progress=False)['Close']\n",
    "\n",
    "features_df = compute_features(stock, stock_prices_df['Close'], market_close_df, window)\n",
    "\n",
    "labels = la2.get_series_labels(stock_prices_df['Close'][window:], 0.05)\n",
    "labels[labels == -1] = 0\n",
    "\n",
    "data_df = pd.concat([stock_prices_df[window:], features_df], axis=1)\n",
    "data_df['Label'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt = Backtest(data_df, XGB2StateStrategy, cash=10_000)\n",
    "\n",
    "# Run the backtest\n",
    "stats = bt.run()\n",
    "print(stats)\n",
    "\n",
    "# Plot the results\n",
    "bt.plot(filename='backtests/{}_simple.html'.format(stock))\n",
    "\n",
    "# Print prediction accuracy\n",
    "print('Model Accuracy =', accuracy_score(labels[:-1], predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "be4699923af4a0966460344151ab36a29c6396054de8635ccd79f4872230fc95"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
